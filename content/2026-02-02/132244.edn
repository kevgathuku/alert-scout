[{:rule-id "rule-ai", :item {:feed-id "hn-frontpage", :item-id "https://news.ycombinator.com/item?id=46854999", :title "Claude Code is suddenly everywhere inside Microsoft", :link "https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad", :published-at #inst "2026-02-02T11:58:58.000-00:00", :content "Article URL: https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad Comments URL: https://news.ycombinator.com/item?id=46854999 Points: 47 # Comments: 41"}, :excerpts [{:text "Claude Code is suddenly everywhere inside Microsoft", :matched-terms ["claude"], :source :title} {:text "... https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad Comments URL:...", :matched-terms ["claude"], :source :content}]} {:rule-id "clojure", :item {:feed-id "planet-clojure", :item-id "https://building.nubank.com/?p=35917", :title "Building AI agentes in practice with Clojure", :link "https://building.nubank.com/building-ai-agentes-in-practice-with-clojure/", :published-at #inst "2026-02-02T10:00:00.000-00:00", :content "During Clojure South, Marlon Silva, Senior Software Engineer at Nubank, shared his perspective on a recurring challenge for software engineers working with AI today: how to move beyond using AI assistants and start engineering reliable, task-oriented AI agents. According to Marlon, the industry has made it increasingly easy to consume AI — APIs, copilots, and assistants are everywhere — but building AI-powered systems still requires engineers to make a series of low-level, often uncomfortable decisions. In his talk, he focused on demystifying those decisions, framing AI not as a black box, but as infrastructure, and integrations that need to be reasoned about explicitly. Rather than presenting a new framework or abstraction layer, Marlon walked through the architectural choices he believes matter most when building agents in practice, and explained why Clojure offers a particularly strong foundation for exploring this space. Infrastructure first: where your models live matters Marlon started by arguing that any serious AI initiative begins with infrastructure — specifically, how teams access models. While this decision is often treated as an implementation detail, he emphasized that it directly impacts scalability, experimentation, security, and integration with existing systems. From his perspective, engineers typically face two options: Direct AI vendors: Marlon noted that these providers are an excellent entry point for individual developers. Signing up is straightforward, APIs are well-documented, and it is possible to start experimenting almost immediately. For learning and early exploration, this path minimizes friction. Cloud providers: For organizations, however, Marlon argued that leveraging existing cloud relationships is usually the better long-term decision. Most companies already have accounts, billing, security controls, and observability in place. Cloud Providers like AWS and GCP make it possible to access models from multiple AI Labs without introducing new suppliers into the stack. According to Marlon, when teams are operating inside an organization, the most pragmatic default is to use the models already available through their cloud providers. This removes procurement overhead and allows engineers to focus on building systems instead of managing vendors. The fragmentation problem: too many APIs Once access to models is established, Marlon pointed out a second, inevitable problem: API fragmentation. Each provider exposes different request formats, parameters, and SDKs, which quickly complicates development and makes experimentation costly. In his talk, Marlon described this fragmentation as one of the first scaling pain points teams encounter when AI moves beyond a single script or proof of concept. To address this, he introduced LiteLLM as a practical unification layer. LiteLLM is a proxy that standardizes access to multiple models and providers behind a single API, regardless of where the model is hosted. Marlon highlighted three concrete benefits of this approach: A unified interface, allowing teams to switch models without rewriting integration code. Centralized observability, creating a single point for logging, debugging, and auditing model interactions. Cost control, which he emphasized as critical. Token usage scales quickly in production, and LiteLLM enables organizations to track and limit usage per team, service, or key. From Marlon’s perspective, this kind of proxy is not an optimization: it becomes foundational infrastructure as soon as AI is part of a real system. Why smaller models often work better for agents Marlon then challenged a common assumption in the AI space: that larger models are always better. For task-oriented AI agents, he argued, this is rarely true. Citing recent research from Nvidia, Marlon explained that Small Language Models (SLMs) are often a better fit for agents designed to execute specific, well-defined actions. According to him, the broad generalization capabilities of large LLMs, models capable of writing essays or long-form prose, are unnecessary for most agent workloads. Using them in these contexts leads to wasted capacity, higher costs, and increased complexity. He outlined several practical advantages of SLMs: Cost efficiency: models like Llama 4 Scout on AWS Bedrock cost orders of magnitude less per token than large proprietary models. Lower energy consumption: making them a more responsible choice at scale and more eco-friendly. Feasible fine-tuning: adapting a 7–10B parameter model to a specific domain is realistic, whereas doing the same with very large models often is not real for most companies. For Marlon, choosing SLMs is not a compromise, as it is an engineering decision aligned with the actual requirements of agent-based systems. Why Clojure fits this problem space From there, Marlon shifted focus to tooling. He explained that AI development is inherently experimental: prompts change, parameters are adjusted, models are swapped, and assumptions are constantly tested. In that context, developer feedback loops matter. This is where Clojure stands out. Marlon described Clojure as an ergonomic language — not because of syntax alone, but because of its REPL-driven development model. The ability to evaluate functions incrementally, inspect results immediately, and iterate without restarting an application fundamentally changes how engineers explore problem spaces. In his experience, this interactive workflow aligns closely with how AI systems are built and refined.Beyond the REPL, Marlon highlighted two interoperability advantages: Java interoperability: Because Clojure runs on the JVM, it has seamless access to the Java ecosystem. Cloud SDKs, HTTP clients, observability tools, and mature libraries are immediately available. Python interoperability: With libraries such as libpython-clj, Clojure can import and execute Python code directly. While not as seamless as Java interop, this capability allows engineers to reuse Python-based AI tooling without abandoning Clojure’s interactive workflow. For Marlon, this combination makes Clojure a strong orchestration layer for AI systems that need to integrate with multiple ecosystems. From theory to practice: the live demonstration To make these ideas concrete, Marlon walked through a live demonstration. He started with simple Python scripts that sent text, images, and PDFs to Bedrock-hosted models via a local LiteLLM proxy. These examples established a baseline using familiar tooling. Next, he reproduced the same workflows in Clojure by importing the Python LiteLLM package directly into the Clojure runtime. Python functions were called from Clojure code, with inputs and outputs handled interactively. According to Marlon, the most important part of the demo was not that this approach works, but how it changes the development experience. Python-based workflows often require frequent context switching — editing files, running scripts, and restarting processes. With Clojure and the REPL, the entire feedback loop stays inside the editor. For exploratory domains like AI, Marlon argued, this difference directly translates into faster iteration and deeper focus. Conclusion Marlon closed by emphasizing that AI agents remain a young and rapidly evolving field. Libraries, architectures, and best practices are still in flux, which makes flexibility a key requirement. He also offered a note of caution: granting models excessive autonomy without clear boundaries and controls can lead to fragile systems. In his view, frameworks that favour obscure control flow and mostly relies on LLM itself encourages a “ship and pray” approach to AI development. At the same time, Marlon pointed out that new agent architectures are actively emerging from research groups at organizations like Nvidia and DeepMind, signaling that significant changes are still ahead. His conclusion was pragmatic: combining well-chosen infrastructure, models sized to the problem, and tools that favor exploration creates a solid foundation for building AI systems grounded in engineering discipline. The repository shared during the talk serves as a starting point for engineers interested in continuing that exploration. References Small Language Models are the Future of Agentic AI AlphaEvolve: A coding agent for scientific and algorithmic discovery GitHub – marlonjsilva/clj-agents GitHub – clj-python/libpython-clj The post Building AI agentes in practice with Clojure appeared first on Building Nubank."}, :excerpts [{:text "Building AI agentes in practice with Clojure", :matched-terms ["clojure"], :source :title} {:text "During Clojure South, Marlon Silva, Senior Software Engineer at...", :matched-terms ["clojure"], :source :content} {:text "... building agents in practice, and explained why Clojure offers a particularly strong foundation for...", :matched-terms ["clojure"], :source :content}]} {:rule-id "clojure", :item {:feed-id "planet-clojure", :item-id "https://jobs.braveclojure.com/company/3e-nv/listing/clojure-developer/Gp2z0hhNpuSopgpM74nRI", :title "Clojure Developer at 3E nv", :link "https://jobs.braveclojure.com/company/3e-nv/listing/clojure-developer/Gp2z0hhNpuSopgpM74nRI", :published-at #inst "2026-02-02T10:44:08.000-00:00", :content "Clojure Developer at 3E nv Our SaaS Solution SynaptiQ is 3E’s SaaS product, an independent, evolutionary software suite for asset management of renewable energy portfolios (more information on ). SynaptiQ collects near-real time data of more than 20 million devices spread over 10 thousands utility scale and commercial solar and wind sites spread all over the globe. We develop and operate advanced analytical services to enrich the monitoring data by: satellite imaging data, meteorological modelling, advanced system modelling, machine learning & artificial intelligence. The platform combines domains related to big data, high-performance processing, IoT protocols and AI and is the product of the interactions between a multidisciplinary team of developers, scientists, renewable energy architects, electrical engineers, and enthusiast sales that implement, operate and commercialize SynaptiQ worldwide. The added value realized by SynaptiQ is performance improvement and operational cost reduction for its Operations & Maintenance customers. What you will be doing We are looking for a Back-End Developer with experience in Clojure and a passion for creating efficient, scalable, and accessible back-end systems. At 3E, you will have the opportunity to work on meaningful projects that contribute to the advancement of renewable energy technologies and digitalization. Responsabilities Develop, test, and maintain robust, performant, and scalable back-end codebase in accordance with design and product requirements. Identify and optimize performance bottlenecks in the application (and MySQL db) using best practices and techniques. Use Polylith, Reitit, Malli to build APIs which are efficient and maintainable. Design and develop efficient business-logic processors that act on data. Conduct thorough code reviews and enforce good back-end practices to ensure quality and maintainability of code. Collaborate with multidisciplinary teams of developers, scientists, renewable energy architects, electrical engineers, and sales enthusiasts to achieve project goals (in-person or via email/MS Teams). Track project evolution (Jira). Maintain a codebase that is easy to understand, modify, and extend, and adhere to coding standards and best practices. Requirements To fulfil this role we are looking for someone with: Minimum of 3 years of experience in Clojure OR significant open-source contributions which can show a significant level of skill. A proven track record of optimizing performance bottlenecks, enforcing good back-end practices. Good understanding of performance optimization techniques in the context of Clojure & MySQL. Product-based experience – supporting and modifying a product through several years – living with the decisions of the past and building on top of them. Experience with refactoring a codebase as new features are written. Bonus points for: Good profiling skills (JVM profiler). Other lisp languages (e.g SBCL). Knowledge of Docker Benefits Our offices are hidden in the centre of Brussels with a view on a pond, with ducks and a heron bringing a regular visit. In addition to a stimulating atmosphere in a highly motivated group of people**, 3E offers a unique opportunity to further develop yourself in a company/team with an ambitious growth plan, delivering innovative services. Furthermore: Flexible & gliding working hours Open to fully remote candidates An international environment with colleagues of 25+ nationalities and projects in over 100 countries. An open-minded company where everybody can bring their ideas to the table"}, :excerpts [{:text "Clojure Developer at 3E nv", :matched-terms ["clojure"], :source :title} {:text "Clojure Developer at 3E nv Our SaaS Solution SynaptiQ is...", :matched-terms ["clojure"], :source :content} {:text "... for a Back-End Developer with experience in Clojure and a passion for creating efficient, scalable,...", :matched-terms ["clojure"], :source :content}]}]